%TEX program = xelatex
\documentclass[12pt]{article}
\usepackage[a4paper,left=3cm,right=2cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage{enumitem}
\usepackage{mucyrillic}
\usepackage{mumath}
\usepackage{mutables}

\usepackage[style=gost-numeric,sortcites,language=auto,
movenames=false,maxnames=3]{biblatex}

\addbibresource{mvp.bib}
\addbibresource{advances.bib}

\begin{document}

\section{Обзор литературы}

Метод обзора: открыл google scholar и там взял самые цитируемые статьи,
ссылающиеся на две оригинальные
\cite{liuIsolationForest2008}
\cite{liuIsolationBasedAnomalyDetection2012}
.
Сейчас граница выставлена на 50 цитирований. Это 4 книги и около 150 статей.
Статистика примерно следующая:
\begin{itemize}
    \item 25 источников предлагают какие-либо усовершенствования,
    \item 103 источника либо используют оригинальный isoforest в своём пайплайне, либо сравнивают свои алгоритмы с ним, либо просто упоминают о его существовании,
    \item 19 источников осуществляют обзоры разных методов и подходов, упоминая или описывая в том числе изофорест,
    \item 7 источников не упоминают изофорест вообще,
    \item 2 источника найти не удалось.
\end{itemize}


\subsection*{Обсуждаемые усовершенствования изоляционного леса}

Здесь обсудим, какие усовершенствования предлагают различные авторы в доступной литературе.

\subsubsection*{Статический лес}

В статье
\cite{tokovarovProbabilisticGeneralizationIsolation2022}
авторы предлагают проводить выборку пороговых значений для фич неравномерно от
минимума до максимума, а по некоторому построенному на основе данных распределению.
Распределение строится на основе линейной комбинации ядер, где ядра в центре имеют
меньшую плотность вероятности, чем на краях. Таким образом вероятность выбрать из
пороговое значение из плотного региона будет меньше, а разделение -- лучше.

Статьи
\cite{zhouDeepForestAlternative2017}
\cite{zhouDeepForest2019}
посвящены "глубокому лесу". Идея повторяет глубокие нейронные сети. Несколько раз
каскадом повторяем одну и ту же операцию -- строим лес, считаем скоры, приписываем
скоры в дополнение к исходным фичам. Как именно происходит обучение я не догнал,
но в целом подход хороший. Гиперпараметров значительно меньше, чем у нейронок.

Ещё пара статей по дальнейшей проработке глубокого леса:
\cite{utkinDeepForestClassifier2019}
.

Тут
\cite{sunDetectingAnomalousUser2016}
в целом ничего интересного, кроме мысли о том, что изофорест можно применять в т.ч.
и к категориальным данным. При этом сами они применяют его очень странно.

В статье
\cite{vinhDiscoveringOutlyingAspects2016}
коллеги зачем-то выкидывают деревья из изофореста, но зато доказывают интересное
наблюдение: средняя длина изолирующего пути не зависит от размерности для
равномерно распределённых данных. Заодно выводят по-человечески ту самую формулу
для средней длины пути.

Авторы
\cite{linDisorientationDetectionMining2015a},
\cite{zhangIBATDetectingAnomalous2011},
\cite{chenIBOATIsolationBasedOnline2013}
\cite{chenRealTimeDetectionAnomalous2012}
применяют по сути изоляционный лес к географическим координатам машин, чтобы понять,
когда машина уехала куда-то вообще не туда. У их подхода есть интересная особенность.
Они не строят деревьев на траекториях, а прямо задают вопрос "сколько делений выдержит
конкретна эта трактория, если мы будем её изолировать от вот этого сабсемпла
траекторий".

Поступают они совершенно аналогично
\cite{vinhDiscoveringOutlyingAspects2016}
, что намекает, что эта мысль у людей бродит. И правильно бродит -- не всегда есть
возможность нарезать данные в какой-то очевидной топологии. Например, если у нас
данные состоят сплошь из категориальных данных. Как делить тогда? Или если данные
разреженные -- тот же вопрос. Не всегда вообще в данных присутствуют все измерения.
Такой подход в принципе может упростить работу с инженерией фич.

В статьях
\cite{bandaragodaEfficientAnomalyDetection2014a}
\cite{bandaragodaIsolationbasedAnomalyDetection2018}
авторы создают гибрид между LOF и изофорестом. Выглядит любопытно. Но это уже
совсем не деревья получаются. Никакой вероятностной интерпретацией и не пахнет.
Да и во много опирается на понятие расстояния, от которого изофорест удачно
дистанцировался.

Интересная попытка обогатить изофорест -- это extended isolation forest
\cite{haririExtendedIsolationForest2021}
. Вместо выбора случайной фичи выбирается случайное направление. Это хорошая
заявка на успех, но почему-то по тестам в той же статье получается не
суперархишикарно.

Считаю, что причина в том, что идея не доведена до логического
завершения. Посмотрел код -- у них вместо порогового значения скалярного произведения
зачем-то выбирается случайная точка из гиперкуба, ограничивающего данные. Явно есть
возможность нахалявку доработать и получить результат наверняка более впечатляющий.
Либо узнать нечто новое про изоляционный лес.

Чёрт, это уже сделано в
\cite{lesoupleGeneralizedIsolationForest2021}
. Буквально год назад.


В статье
\cite{wuRSForestRapidDensity2014}
приводится подход, где куча всего изменено, а доказательной базы никакой.
Приводится как раз идея оценивать собственно сами распределения, а не матожидание
логарифма. Даже какая-то теория прилеплена, но не видно доказательств, что это
лучше обычного изофореста.

Статья
\cite{yuFilteringRefinementTwoStage2009}
делает что-то относительно интересное и издалека похожее на изоляционный лес. Но только
издалека. Они предлагают двухэтапный подход к поиску аномалий, где в качестве первого этапа
используют построение дерева с минимизацией межгрупповой дисперсии. Этим деревом отсеивают
наиболее плотные участки данных. Вторым этапом считают какие-то своеобрзаные метрики,
основанные на расстояниях. Частично интересно, но расстояния всё обламывают.

Вот тут
\cite{aryalImprovingIForestRelative2014}
интересное предложение
состоит в том, что можно считать скор не как длину пути от корня дерева к листу с аномалией,
а как долю семплов, которую отделяет финальная ветвь. Получается аналог LOF, т.к. задаёт
именно локальный скор семплам. По утверждению авторов получается не хуже самого изофореста.
Стоит взять на вооружение.

Вот здесь
\cite{chenIsolationForestAlternative2019}
какое-то не очень очевидное применение изофореста для задачи поиска полезных ископаемых.
Упоминаю в этом разделе, т.к. такое применение может намекнуть на неочевидную интерпретацию
метода.

Статья
\cite{zhouRelevanceFeatureMapping2012}
предлагает интересный наркоманистый способ использования изофореста для поиска релевантных
данных. Точнее даже две интересных роли для изофореста. Первая роль -- это трансформация
фич. Генерируется пачка деревьев, и скор от каждого дерева является новой фичей. В целом
это соответствует каким-то мыслям про Deep Forest.

Вторая роль -- это высчитывание скоров "похожести". Если у нас есть какой-то семпл, для которого
мы хотим найти похожих, сперва считаем веса по всем фичам. Веса принимают значения от -1 (для самых аномальных данных) до 1 (для самых регулярных).
Потом с этими весами считаются средневзвешенные скоры у всех остальных данных. Похожие данные
имеют скор больше, чем непохожие.

В статье
\cite{elnourDualIsolationForestsBasedAttackDetection2020}
предлагают использовать двойной изоляционный лес для поиска аномалий. Строятся два леса --
один на исходных данных, а другой на данных после прокручивания через PCA. Выбросом
считается объединение выбросов этих лесов. Видимо, они пришли к такому алгоритму чисто
перебором. Какие-то аномалии хорошо отлавливал один лес, а какие-то -- другой.

Авторы
\cite{taoParallelAlgorithmNetwork2018} 
решили удивить мир тем, что распараллелили изофорест на спарке и хадупе. Выглядит немного
странно. А что, кто-то сомневался, что это можно будет легко сделать?

В статье
\cite{liuOptimizedComputationalFramework2018}
под флагом оптимизации сделали из изофореста ещё один вариант случайного леса.

\subsubsection*{Кластеры аномалий}

Много кто заинтересован в поиске целых кластеров аномалий. Глубоко в эти статьи
ещё не вчитывался.

Авторы оригинальной статьи предлагали накрутить поиск аномальных кластеров в
\cite{liuDetectingClusteredAnomalies2010}
. 

Что именно сделали в статье
\cite{karczmarekKMeansbasedIsolationForest2020}
я искренне не понял. Они что-то как-то порезали на кластеры. Как -- хрен знает.
Вчитываться в детали пока не собираюсь, т.к. направление мыслей не впечатляет.


\subsubsection*{Стриминг}

Про стриминг вообще чёртовы наркоманы пишут. Либо они прикидываются.

Авторы
\cite{dingAnomalyDetectionApproach2013}
предлагают резать входные данные на блоки и на основе этих блоков строить новые 
леса. Написано достаточно мутно, поэтому не ясно ни то, как они считают скоры
блоков, ни то, при каких обстоятельствах они считают, что нашли аномалию. Очень
скользкие типы.

Очередная статья про стриминг
\cite{muClassificationStreamingEmerging2017}
мутная. Режут данные на разные виды аномальностей -- подальше от регулярных
данных и поближе, покрывают шарами те, которые поближе, доращивают деревья.
Какая-то откровенная дичь, которую я вообще не затащил.

Ещё про стриминг --
\cite{guhaRobustRandomCut2016}
. Здесь уже интереснее. Сперва авторы меняют алгоритм построения дерева --
зачем-то вешают разные веса на разные размерности в зависимости от диаметра
данных на этой размерности. Таким образом вновь убивая независимость изофореста
от определения расстояния. Но зато у них какие-то свои прикольные мысли на тему того,
как считать скор аномалий и как жить в стриме.

Ещё про стриминг --
\cite{wuRSForestRapidDensity2014}
. Та самая статья, обсуждающая то, как оценивать именно плотность вероятности.
В названии сказано про стриминг, но конкретно стриминга внутри там очень немного.


\subsubsection*{Активное обучение}

В статье
\cite{pugginiEnhancedVariableSelection2018}
предлагают попробовать интересный вид
уменьшения размерностей -- модернизировать PCA по SVD-разложению минимаксом.
Если верить их графикам, штука очень даже хорошо рабочая.

Что по лесу, то 
авторы делают важное наблюдение, что при наличии парочки размеченных аномалий уже
можно собрать статистики по тому, какие фичи позволяют эти аномалии дискриминировать
(аналогичную мысль повторяют авторы статьи
\cite{gavaiDetectingInsiderThreat2015}
).

Отдельно интересно, что эти коллеги фитят F-распределение к скорам аномальности
семплов на изоляционном лесе. Это какой-то теоретический результат?

Статьи
\cite{siddiquiFeedbackGuidedAnomalyDiscovery2018}
и
\cite{dasIncorporatingExpertFeedback}
обсуждаются здесь.


\subsubsection*{Общеметодическое}

Отдельно от всех упомяну статью
\cite{camposEvaluationUnsupervisedOutlier2016}
, которая обсуждает, как вообще измерять и сравнивать перморм алгоритмов поиска
аномалий. Статья не впечатляющая на первый взгляд, но возможно что-то полезное
для наших дел можно оттуда подчерпнуть.

Другая статья для отдельного упоминания --
\cite{aggarwalTheoreticalFoundationsAlgorithms2015}
. Авторы обсуждают вопросы bias-variance tradeoff, bagging и subsampling в применении
к поиску аномалий.

Ещё отдельно интересно почитать повнимательнее книгу
\cite{aggarwalOutlierEnsembles2017}
. Там хоть всё по поверхности, но зато ссылок много, к которым следует приглянуться.

Есть какая-то странная мысль про то, как на самом деле стоит изображать найденные выбросы.
Типа как найти среди двумерных графиков тот набор, который наилучшим образом объяснит, что именно отличает выбросы от регулярных данных
\cite{guptaOutlierDetectionLookOut2019}
.

\subsection*{Список источников}
\printbibliography[heading=none]
\end{document}
